{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torchnlp.modules.transformer.sublayers import MultiHeadAttention, PositionwiseFeedForward\n",
    "from torchnlp.modules.normalization import LayerNorm\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Represents one Encoder layer of the Transformer Encoder\n",
    "    Refer Fig. 1 in https://arxiv.org/pdf/1706.03762.pdf\n",
    "    NOTE: The layer normalization step has been moved to the input as per latest version of T2T\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, total_key_depth, total_value_depth, filter_size, num_heads,\n",
    "                 bias_mask=None, layer_dropout=0.0, attention_dropout=0.0, relu_dropout=0.0):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            hidden_size: Hidden size\n",
    "            total_key_depth: Size of last dimension of keys. Must be divisible by num_head\n",
    "            total_value_depth: Size of last dimension of values. Must be divisible by num_head\n",
    "            output_depth: Size last dimension of the final output\n",
    "            filter_size: Hidden size of the middle layer in FFN\n",
    "            num_heads: Number of attention heads\n",
    "            bias_mask: Masking tensor to prevent connections to future elements\n",
    "            layer_dropout: Dropout for this layer\n",
    "            attention_dropout: Dropout probability after attention (Should be non-zero only during training)\n",
    "            relu_dropout: Dropout probability after relu in FFN (Should be non-zero only during training)\n",
    "        \"\"\"\n",
    "        \n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.multi_head_attention = MultiHeadAttention(hidden_size, total_key_depth, total_value_depth, \n",
    "                                                       hidden_size, num_heads, bias_mask, attention_dropout)\n",
    "        \n",
    "        self.positionwise_feed_forward = PositionwiseFeedForward(hidden_size, filter_size, hidden_size,\n",
    "                                                                 layer_config='cc', padding = 'both', \n",
    "                                                                 dropout=relu_dropout)\n",
    "        self.dropout = nn.Dropout(layer_dropout)\n",
    "        self.layer_norm_mha = LayerNorm(hidden_size)\n",
    "        self.layer_norm_ffn = LayerNorm(hidden_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        \n",
    "        # Layer Normalization\n",
    "        x_norm = self.layer_norm_mha(x)\n",
    "        input_ = x_norm\n",
    "        # Multi-head attention\n",
    "        y, attn, bias_mask = self.multi_head_attention(x_norm, x_norm, x_norm)\n",
    "        \n",
    "        # Dropout and residual\n",
    "        x = self.dropout(x + y)\n",
    "        \n",
    "        # Layer Normalization\n",
    "        x_norm = self.layer_norm_ffn(x)\n",
    "        \n",
    "        # Positionwise Feedforward\n",
    "        y = self.positionwise_feed_forward(x_norm)\n",
    "        \n",
    "        # Dropout and residual\n",
    "        y = self.dropout(x + y)\n",
    "        \n",
    "        return y, input_, attn, bias_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = []\n",
    "atten_hook = []\n",
    "def hook(model, in_f, out_f):\n",
    "    print(\"hooking\")\n",
    "    model_names.append(model.__class__)\n",
    "    atten_hook.append((in_f, out_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = EncoderLayer(30, 30,30, 20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7fcdcc5d7210>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.multi_head_attention.register_forward_hook(hook=hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hooking\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 2, 30)\n",
    "output=tt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atten_hook[0][1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.EncoderLayer"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " False\n",
      "multi_head_attention True\n",
      "multi_head_attention.query_linear False\n",
      "multi_head_attention.key_linear False\n",
      "multi_head_attention.value_linear False\n",
      "multi_head_attention.output_linear False\n",
      "multi_head_attention.dropout False\n",
      "positionwise_feed_forward False\n",
      "positionwise_feed_forward.layers False\n",
      "positionwise_feed_forward.layers.0 False\n",
      "positionwise_feed_forward.layers.0.pad False\n",
      "positionwise_feed_forward.layers.0.conv False\n",
      "positionwise_feed_forward.layers.1 False\n",
      "positionwise_feed_forward.layers.1.pad False\n",
      "positionwise_feed_forward.layers.1.conv False\n",
      "positionwise_feed_forward.relu False\n",
      "positionwise_feed_forward.dropout False\n",
      "dropout False\n",
      "layer_norm_mha False\n",
      "layer_norm_ffn False\n"
     ]
    }
   ],
   "source": [
    "for name, m, in tt.named_modules():\n",
    "    (name, isinstance(m, MultiHeadAttention))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/zijiao/research/atal'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchnlp.data.conll import conll2000_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = conll2000_dataset(50)\n",
    "\n",
    "type(con)\n",
    "\n",
    "iters = con['iters']\n",
    "\n",
    "train_iter = iters[0]\n",
    "\n",
    "type(train_iter)\n",
    "\n",
    "from collections.abc import Iterable\n",
    "\n",
    "train_data = list(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,  686,    7,  ...,    1,    1,    1],\n",
       "        [   2,   11,  148,  ...,    1,    1,    1],\n",
       "        [   2, 1090,   14,  ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [   2, 2894,  224,  ...,    1,    1,    1],\n",
       "        [   2,    5,  183,  ...,    1,    1,    1],\n",
       "        [   2,    5, 1298,  ...,    1,    1,    1]], device='cuda:0')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].inputs_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2,  2,  3,  ...,  1,  1,  1],\n",
       "         [ 2, 34,  7,  ...,  1,  1,  1],\n",
       "         [ 2,  7, 19,  ...,  1,  1,  1],\n",
       "         ...,\n",
       "         [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "         [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "         [ 1,  1,  1,  ...,  1,  1,  1]],\n",
       "\n",
       "        [[ 2,  2,  3,  ...,  1,  1,  1],\n",
       "         [ 2, 36,  9,  ...,  1,  1,  1],\n",
       "         [ 2, 52,  6,  ...,  1,  1,  1],\n",
       "         ...,\n",
       "         [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "         [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "         [ 1,  1,  1,  ...,  1,  1,  1]],\n",
       "\n",
       "        [[ 2,  2,  3,  ...,  1,  1,  1],\n",
       "         [ 2, 37, 11,  ...,  1,  1,  1],\n",
       "         [ 2, 28, 10,  ...,  1,  1,  1],\n",
       "         ...,\n",
       "         [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "         [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "         [ 1,  1,  1,  ...,  1,  1,  1]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2,  2,  3,  ...,  1,  1,  1],\n",
       "         [ 2, 36, 18,  ...,  1,  1,  1],\n",
       "         [ 2, 34,  7,  ...,  1,  1,  1],\n",
       "         ...,\n",
       "         [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "         [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "         [ 1,  1,  1,  ...,  1,  1,  1]],\n",
       "\n",
       "        [[ 2,  2,  3,  ...,  1,  1,  1],\n",
       "         [ 2, 30, 13,  ...,  1,  1,  1],\n",
       "         [ 2, 18, 12,  ...,  1,  1,  1],\n",
       "         ...,\n",
       "         [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "         [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "         [ 1,  1,  1,  ...,  1,  1,  1]],\n",
       "\n",
       "        [[ 2,  2,  3,  ...,  1,  1,  1],\n",
       "         [ 2, 30, 13,  ...,  1,  1,  1],\n",
       "         [ 2, 52,  4,  ...,  1,  1,  1],\n",
       "         ...,\n",
       "         [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "         [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "         [ 1,  1,  1,  ...,  1,  1,  1]]], device='cuda:0')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].inputs_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8,  ..., 1, 1, 1],\n",
       "        [2, 6, 5,  ..., 1, 1, 1],\n",
       "        [2, 5, 5,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [2, 5, 4,  ..., 1, 1, 1],\n",
       "        [2, 5, 4,  ..., 1, 1, 1],\n",
       "        [2, 5, 4,  ..., 1, 1, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where is tags\n",
    "train_data[0].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "con2 = conll2000_dataset(50)\n",
    "\n",
    "iters_2 = con2['iters']\n",
    "\n",
    "train_iter_2 = iters_2[0]\n",
    "\n",
    "\n",
    "from collections.abc import Iterable\n",
    "\n",
    "train_data_2 = list(train_iter_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,  686,    7,  ...,    1,    1,    1],\n",
       "        [   2,   11,  148,  ...,    1,    1,    1],\n",
       "        [   2, 1090,   14,  ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [   2, 2894,  224,  ...,    1,    1,    1],\n",
       "        [   2,    5,  183,  ...,    1,    1,    1],\n",
       "        [   2,    5, 1298,  ...,    1,    1,    1]], device='cuda:0')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].inputs_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,  686,    7,  ...,    1,    1,    1],\n",
       "        [   2,   11,  148,  ...,    1,    1,    1],\n",
       "        [   2, 1090,   14,  ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [   2, 2894,  224,  ...,    1,    1,    1],\n",
       "        [   2,    5,  183,  ...,    1,    1,    1],\n",
       "        [   2,    5, 1298,  ...,    1,    1,    1]], device='cuda:0')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_2[0].inputs_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   2,   10,    9,  ...,    1,    1,    1],\n",
       "         [   2,  477, 3164,  ...,    1,    1,    1],\n",
       "         [   2,    5, 2165,  ...,    1,    1,    1],\n",
       "         ...,\n",
       "         [   2,   36,   62,  ...,    1,    1,    1],\n",
       "         [   2,   35, 4343,  ...,    1,    1,    1],\n",
       "         [   2,  449,  348,  ...,    1,    1,    1]], device='cuda:0'),\n",
       " tensor([[   2,   10,    9,  ...,    1,    1,    1],\n",
       "         [   2,  477, 3164,  ...,    1,    1,    1],\n",
       "         [   2,    5, 2165,  ...,    1,    1,    1],\n",
       "         ...,\n",
       "         [   2,   36,   62,  ...,    1,    1,    1],\n",
       "         [   2,   35, 4343,  ...,    1,    1,    1],\n",
       "         [   2,  449,  348,  ...,    1,    1,    1]], device='cuda:0'))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1].inputs_word, train_data_2[1].inputs_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchnlp.data.conll import conll2000_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "con2 = conll2000_dataset(50)\n",
    "\n",
    "iters_2 = con2['iters']\n",
    "\n",
    "train_iter_2 = iters_2[0]\n",
    "\n",
    "\n",
    "from collections.abc import Iterable\n",
    "\n",
    "train_data_2 = list(train_iter_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,  686,    7,  ...,    1,    1,    1],\n",
       "        [   2,   11,  148,  ...,    1,    1,    1],\n",
       "        [   2, 1090,   14,  ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [   2, 2894,  224,  ...,    1,    1,    1],\n",
       "        [   2,    5,  183,  ...,    1,    1,    1],\n",
       "        [   2,    5, 1298,  ...,    1,    1,    1]], device='cuda:0')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_2[0].inputs_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter_2.shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter_2.init_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_2_2 = list(train_iter_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,  686,    7,  ...,    1,    1,    1],\n",
       "        [   2,   11,  148,  ...,    1,    1,    1],\n",
       "        [   2, 1090,   14,  ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [   2, 2894,  224,  ...,    1,    1,    1],\n",
       "        [   2,    5,  183,  ...,    1,    1,    1],\n",
       "        [   2,    5, 1298,  ...,    1,    1,    1]], device='cuda:0')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_2_2[0].inputs_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] finished the data shuffle problem\n",
    "- [x] make train, shufffle, make evaluate not shuffle\n",
    "- [x] put save atttention in evalaution part\n",
    "- [x] check embedding, solved, it is in the init part of Tagger\n",
    "- [x] understand the size of multiheadattention output\n",
    "- [x] test load evaluation\n",
    "    - [x] save it\n",
    "    - [x] load it and properly for each example\n",
    "- [ ] finish the adversarial loss and start training **Nearly**\n",
    "REST\n",
    "---\n",
    "- [ ] use random pre attention as baseline, to compare the divergence\n",
    "- [ ] use above to test guiding classifiers\n",
    "Anlysis\n",
    "- [ ] compare div with baseline\n",
    "- [ ] say about generalization\n",
    "- [ ] say about probing classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchnlp.modules.transformer import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchnlp.chunk import hparams_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchnlp.tasks.sequence_tagging.transformer_tagger import TransformerTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = hparams_map[TransformerTagger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = hparams.update(adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Encoder(hparams.embedding_size_word,\n",
    "               hparams.hidden_size,\n",
    "               hparams.num_hidden_layers,\n",
    "               hparams.num_heads,\n",
    "               hparams.attention_key_channels,\n",
    "               hparams.attention_value_channels,\n",
    "               hparams.filter_size,\n",
    "               hparams.max_length,\n",
    "               hparams.input_dropout,\n",
    "               hparams.dropout,\n",
    "               hparams.attention_dropout,\n",
    "               hparams.relu_dropout,\n",
    "               use_mask=False,\n",
    "               adv=hparams.adversarial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 128)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.embedding_size_word, hparams.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = torch.ones((hparams.embedding_size_word, hparams.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchnlp.chunk import conll2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torchnlp.data.conll:---------- CONLL 2000 Chunking ---------\n",
      "INFO:torchnlp.data.conll:Train size: 8042\n",
      "INFO:torchnlp.data.conll:Validation size: 894\n",
      "INFO:torchnlp.data.conll:Test size: 2012\n",
      "INFO:torchtext.vocab:Loading vectors from .vector_cache/glove.6B.200d.txt.pt\n",
      "INFO:torchtext.vocab:Loading vectors from .vector_cache/charNgram.txt.pt\n",
      "INFO:torchnlp.data.conll:Input vocab size:19032\n",
      "INFO:torchnlp.data.conll:Tagset size: 25\n"
     ]
    }
   ],
   "source": [
    "conll = conll2000(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = conll['vocabs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = TransformerTagger(hparams, **{'vocabs':vocabs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = conll['iters'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batchs = list(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerTagger(\n",
       "  (embedding_word): Embedding(19032, 300)\n",
       "  (output_layer): CRFOutputLayer(\n",
       "    (output_projection): Linear(in_features=128, out_features=25, bias=True)\n",
       "    (crf): CRF()\n",
       "  )\n",
       "  (transformer_enc): Encoder(\n",
       "    (embedding_proj): Linear(in_features=300, out_features=128, bias=False)\n",
       "    (encoders): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (multi_head_attention): MultiHeadAttention(\n",
       "          (query_linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (key_linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (value_linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (output_linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (positionwise_feed_forward): PositionwiseFeedForward(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (layer_norm_mha): LayerNorm()\n",
       "        (layer_norm_ffn): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm()\n",
       "    (input_dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (criterion): KLDivLoss()\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "haha = test(train_batchs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"76pt\" height=\"29pt\"\n",
       " viewBox=\"0.00 0.00 76.00 29.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 25)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-25 72,-25 72,4 -4,4\"/>\n",
       "<!-- 94560744603504 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>94560744603504</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"68,-21 0,-21 0,0 68,0 68,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">NoneType</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f2d640d8650>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(haha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16,  8, 10,  ..., 17, 16,  9],\n",
       "        [24, 16, 18,  ..., 17,  8, 21],\n",
       "        [16, 20,  2,  ...,  8,  2, 21],\n",
       "        ...,\n",
       "        [20, 21, 20,  ..., 20,  8, 21],\n",
       "        [20, 18,  8,  ..., 18, 16, 21],\n",
       "        [20,  5, 16,  ...,  2, 16, 21]], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('allennlp': conda)",
   "language": "python",
   "name": "python37664bitallennlpconda6b161ae5cf3e43a6ad2666aa947c4480"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
